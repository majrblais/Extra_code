{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53e63971-8d89-4007-9e94-c4b85a1d9f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marcb\\anaconda3\\envs\\greystone\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow RMSE: 1.5124679338430265\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge, ElasticNet, SGDRegressor, BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Load the data\n",
    "file_path = \"data_nr_benefit_filtered.xlsx\"\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Define columns\n",
    "data_columns = [\n",
    "    'Wetland Type - Provincial Class',\n",
    "    'Wetland Type - Federal Class',\n",
    "    'Water Regime Indicator',\n",
    "    'Specific Vegetation Type',\n",
    "    '% Vegetation Cover for Specific Vegetation Cover Types',\n",
    "    '% High Woody Canopy Cover (>5m)',\n",
    "    'Phragmites present (Y/N)',\n",
    "    'Soil Type',\n",
    "    '% of Surface Water Present',\n",
    "    'Depth of Saturation (cm)',\n",
    "    'Average Depth of Living Moss (cm)',\n",
    "    'Average Total Depth of Organics',\n",
    "    'Average Organic Depth (cm)',\n",
    "    'Hydrogeomorphic Class',\n",
    "    '% Moss Cover'\n",
    "]\n",
    "\n",
    "results_columns = ['NR_Benefit']\n",
    "\n",
    "# Prepare data for regression\n",
    "X = data[data_columns]\n",
    "y = data[results_columns[0]]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load trained models and their weights\n",
    "model_directory = \"NR_benefit_filtered\"\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "# Load TensorFlow model\n",
    "tensorflow_model_filename = './NR_benefit_filtered/TensorFlow_model.h5'\n",
    "model_tf = tf.keras.models.load_model(tensorflow_model_filename)\n",
    "scaler_tf = joblib.load(\"./NR_benefit_filtered/scaler_tf.pkl\")\n",
    "\n",
    "# Standardize the test data for TensorFlow model\n",
    "X_test_scaled_tf = scaler_tf.transform(X_test)\n",
    "\n",
    "# Evaluate the TensorFlow model\n",
    "y_pred_tf = model_tf.predict(X_test_scaled_tf)\n",
    "rmse_tf = mean_squared_error(y_test, y_pred_tf, squared=False)\n",
    "print(f\"TensorFlow RMSE: {rmse_tf}\")\n",
    "\n",
    "# Add TensorFlow model to best_models\n",
    "best_models['TensorFlow'] = (model_tf, y_pred_tf)\n",
    "\n",
    "# Load other models\n",
    "sklearn_model_filenames = [filename for filename in os.listdir(model_directory) if filename.endswith(\"_model.pkl\")]\n",
    "\n",
    "for filename in sklearn_model_filenames:\n",
    "    model_name = filename.split(\"_\")[0]\n",
    "    model = joblib.load(os.path.join(model_directory, filename))\n",
    "    y_pred = model.predict(X_test)\n",
    "    best_models[model_name] = (model, y_pred)\n",
    "\n",
    "# Plot expected vs. predicted results for each model separately and save\n",
    "output_directory = \"model_plots\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "for model_name, (model, y_pred) in best_models.items():\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(y_test, y_pred, color='blue', s=5)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.title(f'Expected vs. Predicted Results for {model_name}')\n",
    "    plt.savefig(os.path.join(output_directory, f\"{model_name}_\" + (results_columns[0]) + \"_plot.png\"))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694c9fec-9c7e-49c6-837f-979dce7226b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
